{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error as mse,r2_score as r2, mean_absolute_error as mae , make_scorer \n",
    "import sklearn.preprocessing as pre\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, TimeSeriesSplit\n",
    "#Linear Models\n",
    "import sklearn.linear_model as lm\n",
    "#Trees - Non-Linear\n",
    "from sklearn.ensemble import RandomForestRegressor as rf\n",
    "from sklearn.ensemble import AdaBoostRegressor as ada\n",
    "\n",
    "#NeuralNet - Piecewise Linear\n",
    "from sklearn.neural_network import MLPRegressor as fnn\n",
    "\n",
    "from main import RollingWindowSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate Model and Store Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set = [[32,53,'vix20',21],[22,63,'vix40',41],[12,73,'vix60',61],[2,83,'vix80',81]]\n",
    "naif = {81:0.05,61:0.08,41:0.11,21:0.15}\n",
    "purge = 5\n",
    "alphaset = [0.0001,0.001,0.01,0.1,1,10,100,1000,10000]\n",
    "maxdepth = {0.0001:3,0.001:5,0.01:10,0.1:15,1:20,10:40,100:80,1000:100,10000:1000}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_test(path,intercept=True):\n",
    "    surface = pd.read_csv(path)\n",
    "    #Restrict database in order to eliminate some outliers concentrated before 2000   940:\n",
    "    surface = surface.loc[300:3800]\n",
    "    surface.reset_index(inplace=True) #Need to reset index cause after slicing index start from 940 and .loc wrongly indenty it\n",
    "    surface.drop(columns='level_0',inplace=True)\n",
    "    cv1 = pd.DataFrame(columns=['alpha','num_opt','VIX2','VIX_Naif','VIX*2','Linear','Ridge','Lasso','Elastic','Huber','RF','FNN'])\n",
    "    cv2 = pd.DataFrame(columns=['alpha','num_opt','VIX2','VIX_Naif','VIX*2','Linear','Ridge','Lasso','Elastic','Huber','RF','FNN'])\n",
    "    \n",
    "    for alpha in alphaset:\n",
    "        result1 = pd.DataFrame(columns=['alpha','num_opt','VIX2','VIX_Naif','VIX*2','Linear','Ridge','Lasso','Elastic','Huber','RF','FNN'],index=[21,41,61,81])\n",
    "        result2 = pd.DataFrame(columns=['alpha','num_opt','VIX2','VIX_Naif','VIX*2','Linear','Ridge','Lasso','Elastic','Huber','RF','FNN'],index=[21,41,61,81])\n",
    "    \n",
    "        \n",
    "#        '''LINEAR REGRESSION'''\n",
    "#    \n",
    "#        for fset in feature_set:\n",
    "#            feature_start , feature_end , vix_code, result_index = fset\n",
    "#          \n",
    "#            Y1_true = []\n",
    "#            Y1_hat  = []\n",
    "#            Y2_true = []\n",
    "#            Y2_hat  = []\n",
    "#\n",
    "#\n",
    "#            for i,j in RollingWindowSplit().split_bounds(surface,1000,30, purge=purge):\n",
    "#                train_start, train_end = i[0], i[1]\n",
    "#                test_start, test_end = j[0], j[1]\n",
    "#                #Split Train Set\n",
    "#                X80_train = surface.iloc[train_start:train_end,range(feature_start,feature_end,1)].values\n",
    "#\n",
    "#                Y1_train= surface.loc[train_start:train_end-1,'var30'].values   \n",
    "#\n",
    "#                VIX_train = surface.loc[train_start:train_end-1,vix_code].values\n",
    "#                Y2_80_train= surface.loc[train_start:train_end-1,'var30'].values - VIX_train\n",
    "#                #We used train_end -1 because .loc() is inclusive of the up bound contrary to .iloc() or range()\n",
    "#\n",
    "#\n",
    "#                #Split Test Set\n",
    "#                X80_test = surface.iloc[test_start:test_end,range(feature_start,feature_end,1)].values\n",
    "#\n",
    "#                Y1_test= surface.loc[test_start:test_end-1,'var30'].values\n",
    "#\n",
    "#                VIX_test = surface.loc[test_start:test_end-1,vix_code].values\n",
    "#                Y2_80_test= surface.loc[test_start:test_end-1,'var30'].values - VIX_test\n",
    "#\n",
    "#\n",
    "#\n",
    "#                '''REGRESSION 1'''\n",
    "#                #Intialize Linear Regressor\n",
    "#                regressor1 = lm.LinearRegression(fit_intercept=intercept)\n",
    "#\n",
    "#                #Fit the Linear Regressor\n",
    "#                regressor1.fit(X80_train,Y1_train)\n",
    "#\n",
    "#                #Predict OOS\n",
    "#                Y1_true.extend(Y1_test)\n",
    "#                Y1_hat.extend(regressor1.predict(X80_test))\n",
    "#\n",
    "#\n",
    "#                '''REGRESSION 2'''\n",
    "#                #Intialize Linear Regressor\n",
    "#                regressor2 = lm.LinearRegression(fit_intercept=intercept)\n",
    "#\n",
    "#                #Fit the Linear Regressor\n",
    "#                regressor2.fit(X80_train,Y2_80_train)\n",
    "#\n",
    "#                #Predict OOS\n",
    "#                Y2_true.extend(Y2_80_test  +  VIX_test)\n",
    "#                Y2_hat.extend(regressor2.predict(X80_test) + VIX_test)\n",
    "#\n",
    "#               \n",
    "#            #Store results in the Results Dataframe\n",
    "#            result1.loc[result_index,'Linear'] = r2(Y1_true,Y1_hat)\n",
    "#            result2.loc[result_index,'Linear'] = r2(Y2_true,Y2_hat)\n",
    "#\n",
    "#           \n",
    "#\n",
    "#        '''RIDGE REGRESSION'''\n",
    "#\n",
    "#\n",
    "#        for fset in feature_set:\n",
    "#            feature_start , feature_end , vix_code, result_index = fset\n",
    "#            Y1_true = []\n",
    "#            Y1_hat  = []\n",
    "#            Y2_true = []\n",
    "#            Y2_hat  = []\n",
    "#           \n",
    "#\n",
    "#            for i,j in RollingWindowSplit().split_bounds(surface,1000,30,purge=purge):\n",
    "#                train_start, train_end = i[0], i[1]\n",
    "#                test_start, test_end = j[0], j[1]\n",
    "#                #Split Train Set\n",
    "#                X80_train = surface.iloc[train_start:train_end,range(feature_start,feature_end,1)].values\n",
    "#                Y1_train= surface.loc[train_start:train_end-1,'var30'].values \n",
    "#                VIX_train = surface.loc[train_start:train_end-1,vix_code].values\n",
    "#                Y2_80_train= surface.loc[train_start:train_end-1,'var30'].values - VIX_train\n",
    "#                #We used train_end -1 because .loc() is inclusive of the up bound contrary to .iloc() or range()\n",
    "#\n",
    "#\n",
    "#                #Split Test Set\n",
    "#                X80_test = surface.iloc[test_start:test_end,range(feature_start,feature_end,1)].values\n",
    "#                Y1_test= surface.loc[test_start:test_end-1,'var30'].values\n",
    "#                VIX_test = surface.loc[test_start:test_end-1,vix_code].values\n",
    "#                Y2_80_test= surface.loc[test_start:test_end-1,'var30'].values - VIX_test\n",
    "#\n",
    "#\n",
    "#\n",
    "#                '''REGRESSION 1'''\n",
    "#                #Intialize Ridge Regressor\n",
    "#                regressor1 = lm.Ridge(alpha=alpha,fit_intercept=intercept,max_iter=2000)\n",
    "#\n",
    "#                #Fit the Ridge Regressor\n",
    "#                regressor1.fit(X80_train,Y1_train)\n",
    "#\n",
    "#                #Predict OOS\n",
    "#                Y1_true.extend(Y1_test)\n",
    "#                Y1_hat.extend(regressor1.predict(X80_test))\n",
    "#\n",
    "#\n",
    "#                '''REGRESSION 2'''\n",
    "#                #Intialize Ridge Regressor\n",
    "#                regressor2 = lm.Ridge(alpha=alpha,fit_intercept=intercept,max_iter=2000)\n",
    "#\n",
    "#                #Fit the Ridge Regressor\n",
    "#                regressor2.fit(X80_train,Y2_80_train)\n",
    "#\n",
    "#                #Predict OOS\n",
    "#                Y2_true.extend(Y2_80_test  +  VIX_test)\n",
    "#                Y2_hat.extend(regressor2.predict(X80_test) +  VIX_test)\n",
    "#\n",
    "#              \n",
    "#            result1.loc[result_index,'Ridge'] = r2(Y1_true,Y1_hat)\n",
    "#            result2.loc[result_index,'Ridge'] = r2(Y2_true,Y2_hat)\n",
    "#\n",
    "#           \n",
    "#        '''VIX80'''\n",
    "#\n",
    "#        for fset in feature_set:\n",
    "#            feature_start , feature_end , vix_code, result_index = fset\n",
    "#            Y1_true = []\n",
    "#            Y1_hat  = []\n",
    "#            Y2_true = []\n",
    "#            Y2_hat  = []\n",
    "#\n",
    "#\n",
    "#            for i,j in RollingWindowSplit().split_bounds(surface,1000,30, purge=purge):\n",
    "#                train_start, train_end = i[0], i[1]\n",
    "#                test_start, test_end = j[0], j[1]\n",
    "#                #Split Train Set\n",
    "#                X80_train = surface.iloc[train_start:train_end,range(feature_start,feature_end,1)].values\n",
    "#                Y1_train= surface.loc[train_start:train_end-1,'var30'].values   \n",
    "#                VIX_train = surface.loc[train_start:train_end-1,vix_code].values\n",
    "#                Y2_80_train= surface.loc[train_start:train_end-1,'var30'].values - VIX_train\n",
    "#                #We used train_end -1 because .loc() is inclusive of the up bound contrary to .iloc() or range()\n",
    "#\n",
    "#\n",
    "#                #Split Test Set\n",
    "#                X80_test = surface.iloc[test_start:test_end,range(feature_start,feature_end,1)].values\n",
    "#                Y1_test= surface.loc[test_start:test_end-1,'var30'].values\n",
    "#                VIX_test = surface.loc[test_start:test_end-1,vix_code].values\n",
    "#                Y2_80_test= surface.loc[test_start:test_end-1,'var30'].values - VIX_test\n",
    "#\n",
    "#\n",
    "#\n",
    "#                '''REGRESSION 1'''\n",
    "#                #Intialize VIX Regressor\n",
    "#                #regressor1 = lm.LinearRegression()\n",
    "#\n",
    "#                #Predict OOS\n",
    "#                Y1_true.extend(Y1_test)\n",
    "#                Y1_hat.extend(VIX_test)\n",
    "#\n",
    "#\n",
    "#                '''REGRESSION 2'''\n",
    "#                #Intialize VIX Regressor\n",
    "#                #regressor2 = lm.LinearRegression()\n",
    "#\n",
    "#                #Predict OOS\n",
    "#                Y2_true.extend(Y2_80_test  +  VIX_test)\n",
    "#                Y2_hat.extend(VIX_test)\n",
    "#\n",
    "#            #Store results in the Results Dataframe\n",
    "#            result1.loc[result_index,'VIX*2'] = r2(Y1_true,Y1_hat)\n",
    "#            result2.loc[result_index,'VIX*2'] = r2(Y2_true,Y2_hat)\n",
    "#\n",
    "#        '''VIX Naif'''\n",
    "#\n",
    "#\n",
    "#        for fset in feature_set:\n",
    "#            feature_start , feature_end , vix_code, result_index = fset\n",
    "#            Y1_true = []\n",
    "#            Y1_hat  = []\n",
    "#            Y2_true = []\n",
    "#            Y2_hat  = []\n",
    "#\n",
    "#\n",
    "#            for i,j in RollingWindowSplit().split_bounds(surface,1000,30, purge=purge):\n",
    "#                train_start, train_end = i[0], i[1]\n",
    "#                test_start, test_end = j[0], j[1]\n",
    "#                #Split Train Set\n",
    "#                X80_train = surface.iloc[train_start:train_end,range(feature_start,feature_end,1)].values\n",
    "#                Y1_train= surface.loc[train_start:train_end-1,'var30'].values   \n",
    "#                VIX_train = surface.loc[train_start:train_end-1,vix_code].values \n",
    "#                Y2_80_train= surface.loc[train_start:train_end-1,'var30'].values - VIX_train\n",
    "#                #We used train_end -1 because .loc() is inclusive of the up bound contrary to .iloc() or range()\n",
    "#\n",
    "#\n",
    "#                #Split Test Set\n",
    "#                X80_test = surface.iloc[test_start:test_end,range(feature_start,feature_end,1)].values\n",
    "#                Y1_test= surface.loc[test_start:test_end-1,'var30'].values\n",
    "#                VIX_test = surface.loc[test_start:test_end-1,vix_code].values\n",
    "#                Y2_80_test= surface.loc[test_start:test_end-1,'var30'].values - VIX_test\n",
    "#\n",
    "#\n",
    "#\n",
    "#                '''REGRESSION 1'''\n",
    "#                #Intialize VIX Regressor\n",
    "#                #regressor1 = lm.LinearRegression()\n",
    "#\n",
    "#                #Predict OOS\n",
    "#                Y1_true.extend(Y1_test)\n",
    "#                Y1_hat.extend(VIX_test*(1+naif[result_index]))\n",
    "#\n",
    "#\n",
    "#                '''REGRESSION 2'''\n",
    "#                #Intialize VIX Regressor\n",
    "#                #regressor2 = lm.LinearRegression()\n",
    "#\n",
    "#                #Predict OOS\n",
    "#                Y2_true.extend(Y2_80_test  +  VIX_test)\n",
    "#                Y2_hat.extend(VIX_test*(1+naif[result_index]))\n",
    "#\n",
    "#            #Store results in the Results Dataframe\n",
    "#            result1.loc[result_index,'VIX_Naif'] = r2(Y1_true,Y1_hat)\n",
    "#            result2.loc[result_index,'VIX_Naif'] = r2(Y2_true,Y2_hat)\n",
    "#\n",
    "#\n",
    "#\n",
    "#        '''HUBER REGRESSION'''\n",
    "#\n",
    "#\n",
    "#\n",
    "#        for fset in feature_set:\n",
    "#            feature_start , feature_end , vix_code, result_index = fset\n",
    "#           \n",
    "#            Y1_true = []\n",
    "#            Y1_hat  = []\n",
    "#            Y2_true = []\n",
    "#            Y2_hat  = []\n",
    "#\n",
    "#            for i,j in RollingWindowSplit().split_bounds(surface,1000,30, purge=purge):\n",
    "#                train_start, train_end = i[0], i[1]\n",
    "#                test_start, test_end = j[0], j[1]\n",
    "#                #Split Train Set\n",
    "#                X80_train = surface.iloc[train_start:train_end,range(feature_start,feature_end,1)].values\n",
    "#                Y1_train= surface.loc[train_start:train_end-1,'var30'].values   \n",
    "#                VIX_train = surface.loc[train_start:train_end-1,vix_code].values\n",
    "#                Y2_80_train= surface.loc[train_start:train_end-1,'var30'].values - VIX_train\n",
    "#                #We used train_end -1 because .loc() is inclusive of the up bound contrary to .iloc() or range()\n",
    "#\n",
    "#\n",
    "#                #Split Test Set\n",
    "#                X80_test = surface.iloc[test_start:test_end,range(feature_start,feature_end,1)].values\n",
    "#                Y1_test= surface.loc[test_start:test_end-1,'var30'].values\n",
    "#                VIX_test = surface.loc[test_start:test_end-1,vix_code].values\n",
    "#                Y2_80_test= surface.loc[test_start:test_end-1,'var30'].values - VIX_test\n",
    "#\n",
    "#\n",
    "#\n",
    "#                '''REGRESSION 1'''\n",
    "#                #Intialize Huber Regressor\n",
    "#                regressor1 = lm.HuberRegressor(alpha=alpha,fit_intercept=intercept,max_iter=400)\n",
    "#\n",
    "#                #Fit the Huber Regressor\n",
    "#                regressor1.fit(X80_train,Y1_train)\n",
    "#\n",
    "#                #Predict OOS\n",
    "#                Y1_true.extend(Y1_test)\n",
    "#                Y1_hat.extend(regressor1.predict(X80_test))\n",
    "#\n",
    "#\n",
    "#                '''REGRESSION 2'''\n",
    "#                #Intialize Huber Regressor\n",
    "#                regressor2 = lm.HuberRegressor(alpha=alpha,fit_intercept=intercept,max_iter=400)\n",
    "#\n",
    "#                #Fit the Huber Regressor\n",
    "#                regressor2.fit(X80_train,Y2_80_train)\n",
    "#\n",
    "#                #Predict OOS\n",
    "#                Y2_true.extend(Y2_80_test  +  VIX_test)\n",
    "#                Y2_hat.extend(regressor2.predict(X80_test) +  VIX_test)\n",
    "#\n",
    "#                \n",
    "#            result1.loc[result_index,'Huber'] = r2(Y1_true,Y1_hat)\n",
    "#            result2.loc[result_index,'Huber'] = r2(Y2_true,Y2_hat)\n",
    "#\n",
    "#          \n",
    "#\n",
    "#\n",
    "#        '''LASSO REGRESSION'''\n",
    "#\n",
    "#\n",
    "#        for fset in feature_set:\n",
    "#            feature_start , feature_end , vix_code, result_index = fset\n",
    "#            Y1_true = []\n",
    "#            Y1_hat  = []\n",
    "#            Y2_true = []\n",
    "#            Y2_hat  = []\n",
    "#        \n",
    "#            for i,j in RollingWindowSplit().split_bounds(surface,1000,30,purge=purge):\n",
    "#                train_start, train_end = i[0], i[1]\n",
    "#                test_start, test_end = j[0], j[1]\n",
    "#                #Split Train Set\n",
    "#                X80_train = surface.iloc[train_start:train_end,range(feature_start,feature_end,1)].values\n",
    "#                Y1_train= surface.loc[train_start:train_end-1,'var30'].values \n",
    "#                VIX_train = surface.loc[train_start:train_end-1,vix_code].values\n",
    "#                Y2_80_train= surface.loc[train_start:train_end-1,'var30'].values - VIX_train\n",
    "#                #We used train_end -1 because .loc() is inclusive of the up bound contrary to .iloc() or range()\n",
    "#\n",
    "#\n",
    "#                #Split Test Set\n",
    "#                X80_test = surface.iloc[test_start:test_end,range(feature_start,feature_end,1)].values\n",
    "#                Y1_test= surface.loc[test_start:test_end-1,'var30'].values\n",
    "#                VIX_test = surface.loc[test_start:test_end-1,vix_code].values\n",
    "#                Y2_80_test= surface.loc[test_start:test_end-1,'var30'].values - VIX_test\n",
    "#\n",
    "#\n",
    "#\n",
    "#                '''REGRESSION 1'''\n",
    "#                #Intialize Lasso Regressor\n",
    "#                regressor1 = lm.Lasso(alpha=alpha,fit_intercept=intercept,max_iter=2000)\n",
    "#\n",
    "#                #Fit the Lasso Regressor\n",
    "#                regressor1.fit(X80_train,Y1_train)\n",
    "#\n",
    "#                #Predict OOS\n",
    "#                Y1_true.extend(Y1_test)\n",
    "#                Y1_hat.extend(regressor1.predict(X80_test))\n",
    "#\n",
    "#\n",
    "#                '''REGRESSION 2'''\n",
    "#                #Intialize Lasso Regressor\n",
    "#                regressor2 = lm.Lasso(alpha=alpha,fit_intercept=intercept,max_iter=2000)\n",
    "#\n",
    "#                #Fit the Lasso Regressor\n",
    "#                regressor2.fit(X80_train,Y2_80_train)\n",
    "#\n",
    "#                #Predict OOS\n",
    "#                Y2_true.extend(Y2_80_test  +  VIX_test)\n",
    "#                Y2_hat.extend(regressor2.predict(X80_test) +  VIX_test)\n",
    "#\n",
    "#\n",
    "#            result1.loc[result_index,'Lasso'] = r2(Y1_true,Y1_hat)\n",
    "#            result2.loc[result_index,'Lasso'] = r2(Y2_true,Y2_hat)\n",
    "#\n",
    "#            \n",
    "#\n",
    "#        '''ELASTIC NET'''\n",
    "#\n",
    "#        for fset in feature_set:\n",
    "#            feature_start , feature_end , vix_code, result_index = fset\n",
    "#            \n",
    "#            Y1_true = []\n",
    "#            Y1_hat  = []\n",
    "#            Y2_true = []\n",
    "#            Y2_hat  = []\n",
    "#\n",
    "#\n",
    "#            for i,j in RollingWindowSplit().split_bounds(surface,1000,30,purge=purge):\n",
    "#                train_start, train_end = i[0], i[1]\n",
    "#                test_start, test_end = j[0], j[1]\n",
    "#                #Split Train Set\n",
    "#                X80_train = surface.iloc[train_start:train_end,range(feature_start,feature_end,1)].values\n",
    "#                Y1_train= surface.loc[train_start:train_end-1,'var30'].values \n",
    "#                VIX_train = surface.loc[train_start:train_end-1,vix_code].values\n",
    "#                Y2_80_train= surface.loc[train_start:train_end-1,'var30'].values - VIX_train\n",
    "#                #We used train_end -1 because .loc() is inclusive of the up bound contrary to .iloc() or range()\n",
    "#\n",
    "#\n",
    "#                #Split Test Set\n",
    "#                X80_test = surface.iloc[test_start:test_end,range(feature_start,feature_end,1)].values\n",
    "#                Y1_test= surface.loc[test_start:test_end-1,'var30'].values\n",
    "#                VIX_test = surface.loc[test_start:test_end-1,vix_code].values\n",
    "#                Y2_80_test= surface.loc[test_start:test_end-1,'var30'].values - VIX_test\n",
    "#\n",
    "#\n",
    "#\n",
    "#                '''REGRESSION 1'''\n",
    "#                #Intialize Elastic Regressor\n",
    "#                regressor1 = lm.ElasticNet(alpha=alpha,fit_intercept=intercept,max_iter=2000)\n",
    "#\n",
    "#                #Fit the Elastic Regressor\n",
    "#                regressor1.fit(X80_train,Y1_train)\n",
    "#\n",
    "#                #Predict OOS\n",
    "#                Y1_true.extend(Y1_test)\n",
    "#                Y1_hat.extend(regressor1.predict(X80_test))\n",
    "#\n",
    "#\n",
    "#                '''REGRESSION 2'''\n",
    "#                #Intialize Elastic Regressor\n",
    "#                regressor2 = lm.ElasticNet(alpha=alpha,fit_intercept=intercept,max_iter=2000)\n",
    "#\n",
    "#                #Fit the Elastic Regressor\n",
    "#                regressor2.fit(X80_train,Y2_80_train)\n",
    "#\n",
    "#                #Predict OOS\n",
    "#                Y2_true.extend(Y2_80_test  +  VIX_test)\n",
    "#                Y2_hat.extend(regressor2.predict(X80_test) +  VIX_test)\n",
    "#\n",
    "#\n",
    "#            result1.loc[result_index,'Elastic'] = r2(Y1_true,Y1_hat)\n",
    "#            result2.loc[result_index,'Elastic'] = r2(Y2_true,Y2_hat)\n",
    "            \n",
    "            \n",
    "            \n",
    "        '''FEED-FORWARD NEURAL NET REGRESSION'''\n",
    "\n",
    "        for fset in feature_set:\n",
    "            feature_start , feature_end , vix_code, result_index = fset\n",
    "            Y1_true = []\n",
    "            Y1_hat  = []\n",
    "            Y2_true = []\n",
    "            Y2_hat  = []\n",
    "\n",
    "\n",
    "            for i,j in RollingWindowSplit().split_bounds(surface,1000,30, purge=purge):\n",
    "                train_start, train_end = i[0], i[1]\n",
    "                test_start, test_end = j[0], j[1]\n",
    "                #Split Train Set\n",
    "                X80_train = surface.iloc[train_start:train_end,range(feature_start,feature_end,1)].values\n",
    "                Y1_train= surface.loc[train_start:train_end-1,'var30'].values   \n",
    "                VIX_train = surface.loc[train_start:train_end-1,vix_code].values\n",
    "                Y2_80_train= surface.loc[train_start:train_end-1,'var30'].values - VIX_train\n",
    "                #We used train_end -1 because .loc() is inclusive of the up bound contrary to .iloc() or range()\n",
    "\n",
    "\n",
    "                #Split Test Set\n",
    "                X80_test = surface.iloc[test_start:test_end,range(feature_start,feature_end,1)].values\n",
    "                Y1_test= surface.loc[test_start:test_end-1,'var30'].values\n",
    "                VIX_test = surface.loc[test_start:test_end-1,vix_code].values\n",
    "                Y2_80_test= surface.loc[test_start:test_end-1,'var30'].values - VIX_test\n",
    "\n",
    "\n",
    "\n",
    "                '''REGRESSION 1'''\n",
    "                #Intialize FNN Regressor\n",
    "                regressor1 = fnn(hidden_layer_sizes=(result_index,),alpha=alpha,max_iter=2000,early_stopping=False,shuffle=False,verbose=False)\n",
    "\n",
    "                #Fit the FNN Regressor\n",
    "                regressor1.fit(X80_train,Y1_train)\n",
    "\n",
    "                #Predict OOS\n",
    "                Y1_true.extend(Y1_test)\n",
    "                Y1_hat.extend(regressor1.predict(X80_test))\n",
    "\n",
    "\n",
    "                '''REGRESSION 2'''\n",
    "                #Intialize FNN Regressor\n",
    "                regressor2 = fnn(hidden_layer_sizes=(result_index,),alpha=alpha,max_iter=2000,early_stopping=False,shuffle=False,verbose=False)\n",
    "\n",
    "                #Fit the FNN Regressor\n",
    "                regressor2.fit(X80_train,Y2_80_train)\n",
    "\n",
    "                #Predict OOS\n",
    "                Y2_true.extend(Y2_80_test  +  VIX_test)\n",
    "                Y2_hat.extend(regressor2.predict(X80_test) +  VIX_test)\n",
    "\n",
    "            result1.loc[result_index,'FNN'] = r2(Y1_true,Y1_hat)\n",
    "            result2.loc[result_index,'FNN'] = r2(Y2_true,Y2_hat)\n",
    "\n",
    "\n",
    "        '''RF REGRESSION'''\n",
    "\n",
    "\n",
    "        for fset in feature_set:\n",
    "            feature_start , feature_end , vix_code, result_index = fset\n",
    "            Y1_true = []\n",
    "            Y1_hat  = []\n",
    "            Y2_true = []\n",
    "            Y2_hat  = []\n",
    "\n",
    "\n",
    "            for i,j in RollingWindowSplit().split_bounds(surface,1000,30, purge=purge):\n",
    "                train_start, train_end = i[0], i[1]\n",
    "                test_start, test_end = j[0], j[1]\n",
    "                #Split Train Set\n",
    "                X80_train = surface.iloc[train_start:train_end,range(feature_start,feature_end,1)].values\n",
    "                Y1_train= surface.loc[train_start:train_end-1,'var30'].values   \n",
    "                VIX_train = surface.loc[train_start:train_end-1,vix_code].values\n",
    "                Y2_80_train= surface.loc[train_start:train_end-1,'var30'].values - VIX_train\n",
    "                #We used train_end -1 because .loc() is inclusive of the up bound contrary to .iloc() or range()\n",
    "\n",
    "\n",
    "                #Split Test Set\n",
    "                X80_test = surface.iloc[test_start:test_end,range(feature_start,feature_end,1)].values\n",
    "                Y1_test= surface.loc[test_start:test_end-1,'var30'].values\n",
    "                VIX_test = surface.loc[test_start:test_end-1,vix_code].values\n",
    "                Y2_80_test= surface.loc[test_start:test_end-1,'var30'].values - VIX_test\n",
    "\n",
    "\n",
    "\n",
    "                '''REGRESSION 1'''\n",
    "                #Intialize FNN Regressor\n",
    "                regressor1 = rf(max_depth=maxdepth[alpha],n_estimators=100)\n",
    "\n",
    "                #Fit the FNN Regressor\n",
    "                regressor1.fit(X80_train,Y1_train)\n",
    "\n",
    "                #Predict OOS\n",
    "                Y1_true.extend(Y1_test)\n",
    "                Y1_hat.extend(regressor1.predict(X80_test))\n",
    "\n",
    "\n",
    "                '''REGRESSION 2'''\n",
    "                #Intialize FNN Regressor\n",
    "                regressor2 = rf(max_depth=maxdepth[alpha],n_estimators=100)\n",
    "\n",
    "                #Fit the FNN Regressor\n",
    "                regressor2.fit(X80_train,Y2_80_train)\n",
    "\n",
    "                #Predict OOS\n",
    "                Y2_true.extend(Y2_80_test  +  VIX_test)\n",
    "                Y2_hat.extend(regressor2.predict(X80_test) +  VIX_test)\n",
    "\n",
    "            result1.loc[result_index,'RF'] = r2(Y1_true,Y1_hat)\n",
    "            result2.loc[result_index,'RF'] = r2(Y2_true,Y2_hat)\n",
    "            \n",
    "            \n",
    "            \n",
    "            result1.loc[result_index,'alpha'] = alpha\n",
    "            result2.loc[result_index,'alpha'] = alpha\n",
    "            result1.loc[result_index,'num_opt'] = result_index\n",
    "            result2.loc[result_index,'num_opt'] = result_index\n",
    "        \n",
    "        print(alpha)    \n",
    "        result1.reset_index(drop=True,inplace=True)\n",
    "        cv1 = pd.concat([cv1,result1])\n",
    "        result2.reset_index(drop=True,inplace=True)\n",
    "        cv2 = pd.concat([cv2,result2])\n",
    "             \n",
    "        \n",
    "        \n",
    "    return cv1, cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001\n",
      "0.001\n",
      "0.01\n",
      "0.1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "result1, result2 = regression_test(intercept=True, path='/home/student/surface/Realized Variance/DatasetSPX/Dataset30_withmean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_result2 = pd.DataFrame(columns=['VIX_Naif','VIX*2','Linear','Ridge','Lasso','Elastic','Huber','RF','FNN'],index=[21,41,61,81])\n",
    "result2.reset_index(inplace=True,drop=True)\n",
    "for index in cv_result2.index:\n",
    "    for model in ['VIX_Naif','VIX*2','Linear','Ridge','Lasso','Elastic','Huber','RF','FNN']:\n",
    "        line = result2[result2[model]==result2[(result2.num_opt==index)][[model]].max().values[0]]\n",
    "        cv_result2.loc[index,model] = [line.alpha.values[0],np.round(line[model].values[0],3)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_result1 = pd.DataFrame(columns=['VIX_Naif','VIX*2','Linear','Ridge','Lasso','Elastic','Huber','RF','FNN'],index=[21,41,61,81])\n",
    "result1.reset_index(inplace=True,drop=True)\n",
    "for index in cv_result1.index:\n",
    "    for model in ['VIX_Naif','VIX*2','Linear','Ridge','Lasso','Elastic','Huber','RF','FNN']:\n",
    "        line = result1[result1[model]==result1[(result1.num_opt==index)][[model]].max().values[0]]\n",
    "        cv_result1.loc[index,model] = [line.alpha.values[0],np.round(line[model].values[0],3)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VIX_Naif</th>\n",
       "      <th>VIX*2</th>\n",
       "      <th>Linear</th>\n",
       "      <th>Ridge</th>\n",
       "      <th>Lasso</th>\n",
       "      <th>Elastic</th>\n",
       "      <th>Huber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>[0.0001, 0.17]</td>\n",
       "      <td>[0.0001, 0.12]</td>\n",
       "      <td>[0.0001, 0.257]</td>\n",
       "      <td>[100, 0.289]</td>\n",
       "      <td>[0.0001, 0.275]</td>\n",
       "      <td>[0.0001, 0.274]</td>\n",
       "      <td>[10000, 0.329]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>[0.0001, 0.31]</td>\n",
       "      <td>[0.0001, 0.272]</td>\n",
       "      <td>[0.0001, 0.105]</td>\n",
       "      <td>[10000, 0.276]</td>\n",
       "      <td>[0.0001, 0.228]</td>\n",
       "      <td>[0.0001, 0.232]</td>\n",
       "      <td>[10000, 0.282]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>[0.0001, 0.363]</td>\n",
       "      <td>[0.0001, 0.337]</td>\n",
       "      <td>[0.0001, 0.053]</td>\n",
       "      <td>[10000, 0.264]</td>\n",
       "      <td>[0.0001, 0.228]</td>\n",
       "      <td>[0.0001, 0.203]</td>\n",
       "      <td>[10000, 0.238]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>[0.0001, 0.385]</td>\n",
       "      <td>[0.0001, 0.37]</td>\n",
       "      <td>[0.0001, -0.005]</td>\n",
       "      <td>[10000, 0.245]</td>\n",
       "      <td>[0.0001, 0.21]</td>\n",
       "      <td>[0.001, 0.184]</td>\n",
       "      <td>[10000, 0.226]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           VIX_Naif            VIX*2            Linear           Ridge  \\\n",
       "21   [0.0001, 0.17]   [0.0001, 0.12]   [0.0001, 0.257]    [100, 0.289]   \n",
       "41   [0.0001, 0.31]  [0.0001, 0.272]   [0.0001, 0.105]  [10000, 0.276]   \n",
       "61  [0.0001, 0.363]  [0.0001, 0.337]   [0.0001, 0.053]  [10000, 0.264]   \n",
       "81  [0.0001, 0.385]   [0.0001, 0.37]  [0.0001, -0.005]  [10000, 0.245]   \n",
       "\n",
       "              Lasso          Elastic           Huber  \n",
       "21  [0.0001, 0.275]  [0.0001, 0.274]  [10000, 0.329]  \n",
       "41  [0.0001, 0.228]  [0.0001, 0.232]  [10000, 0.282]  \n",
       "61  [0.0001, 0.228]  [0.0001, 0.203]  [10000, 0.238]  \n",
       "81   [0.0001, 0.21]   [0.001, 0.184]  [10000, 0.226]  "
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VIX_Naif</th>\n",
       "      <th>VIX*2</th>\n",
       "      <th>Linear</th>\n",
       "      <th>Ridge</th>\n",
       "      <th>Lasso</th>\n",
       "      <th>Elastic</th>\n",
       "      <th>Huber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>[0.0001, 0.17]</td>\n",
       "      <td>[0.0001, 0.12]</td>\n",
       "      <td>[0.0001, 0.257]</td>\n",
       "      <td>[100, 0.289]</td>\n",
       "      <td>[0.0001, 0.265]</td>\n",
       "      <td>[0.0001, 0.268]</td>\n",
       "      <td>[10000, 0.329]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>[0.0001, 0.31]</td>\n",
       "      <td>[0.0001, 0.272]</td>\n",
       "      <td>[0.0001, 0.105]</td>\n",
       "      <td>[10000, 0.295]</td>\n",
       "      <td>[0.01, 0.313]</td>\n",
       "      <td>[0.01, 0.313]</td>\n",
       "      <td>[10000, 0.282]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>[0.0001, 0.363]</td>\n",
       "      <td>[0.0001, 0.337]</td>\n",
       "      <td>[0.0001, 0.053]</td>\n",
       "      <td>[10000, 0.278]</td>\n",
       "      <td>[0.01, 0.36]</td>\n",
       "      <td>[0.01, 0.36]</td>\n",
       "      <td>[10000, 0.238]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>[0.0001, 0.385]</td>\n",
       "      <td>[0.0001, 0.37]</td>\n",
       "      <td>[0.0001, -0.005]</td>\n",
       "      <td>[10000, 0.256]</td>\n",
       "      <td>[0.01, 0.384]</td>\n",
       "      <td>[0.01, 0.384]</td>\n",
       "      <td>[10000, 0.226]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           VIX_Naif            VIX*2            Linear           Ridge  \\\n",
       "21   [0.0001, 0.17]   [0.0001, 0.12]   [0.0001, 0.257]    [100, 0.289]   \n",
       "41   [0.0001, 0.31]  [0.0001, 0.272]   [0.0001, 0.105]  [10000, 0.295]   \n",
       "61  [0.0001, 0.363]  [0.0001, 0.337]   [0.0001, 0.053]  [10000, 0.278]   \n",
       "81  [0.0001, 0.385]   [0.0001, 0.37]  [0.0001, -0.005]  [10000, 0.256]   \n",
       "\n",
       "              Lasso          Elastic           Huber  \n",
       "21  [0.0001, 0.265]  [0.0001, 0.268]  [10000, 0.329]  \n",
       "41    [0.01, 0.313]    [0.01, 0.313]  [10000, 0.282]  \n",
       "61     [0.01, 0.36]     [0.01, 0.36]  [10000, 0.238]  \n",
       "81    [0.01, 0.384]    [0.01, 0.384]  [10000, 0.226]  "
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
